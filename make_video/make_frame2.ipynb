{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb25029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import mlflow\n",
    "import json\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import albumentations as A\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "__file__ = \"/workdir/seg-laparo/make_video/main_frame.py\"\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "from utils import *\n",
    "from implementations import *\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Yu Mincho', 'Times New Roman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    device = \"cuda:2\"\n",
    "    multi_gpu = True\n",
    "    multi_device_ids = [2, 3]\n",
    "    class model_info:\n",
    "        model =  \"\"\n",
    "        in_channels = 3\n",
    "        out_channels = 1\n",
    "        batch_size = 32\n",
    "        save_model_path = \"./model_weight/{}/{}/model.pth\"\n",
    "        dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb80460",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "data_dir = os.path.join(current_dir, \"../../data_NuVAT/pancreas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a913907",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(data_dir, \"Case010-2\", \"movie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_DATA = {\n",
    "    \"Case001-1\": [\"175356\", \"176343\", \"177366\", \"178725\"],\n",
    "    \"Case001-2\": [\"000428\", \"004533\", \"008386\", \"008702\"],\n",
    "    \"Case002-1\": [\"207239\", \"210977\", \"211002\", \"214680\"],\n",
    "    \"Case003-2\": [\"008433\", \"012271\", \"014350\", \"015086\"],\n",
    "    \"Case004-1\": [\"147509\", \"148097\", \"149637\", \"150212\"],\n",
    "    \"Case006-1\": [\"208927\", \"209434\", \"215010\", \"217629\"],\n",
    "    \"Case007-1\": [\"122401\", \"122682\", \"132575\", \"132713\"],\n",
    "    \"Case008-1\": [\"216413\", \"217513\", \"218013\", \"223154\"],\n",
    "    \"Case008-2\": [\"002240\", \"003041\", \"008435\", \"013300\"],\n",
    "    \"Case009-2\": [\"107362\", \"108365\", \"111070\", \"111160\"],\n",
    "    \"Case010-2\": [\"140331\", \"152612\", \"152660\", \"153860\"],\n",
    "}\n",
    "\n",
    "# used_model_names = [\"unet_aug1\", \"unet_aug3\", \"bunet_aug3!nd\", \"bunet_aug3!ed_10_5\", \"bunet_aug3!ed_10_3\", \"bunet_aug3!ed_10_1\"]\n",
    "# used_model_names = [\"bunet_aug3!ed_10\", \"bunet_aug3!nd\"]\n",
    "# used_model_names = [\"label\", \"bunet_aug5!ed_10\"]\n",
    "# used_model_names = [\"aunet_aug5!ed_10\"]\n",
    "used_model_names = [\"label\", \"unet_aug1\", \"unet_aug5\", \"nbunet_aug1!ed_10\", \"bunet2_aug1!ed_10\", \"nbunet_aug5!ed_10\", \"bunet2_aug5!ed_10\"]\n",
    "# used_model_names = [\"label\", \"unet_aug1\", \"unet_aug5\"]\n",
    "# used_model_names = [\"label\", \"nbunet_aug1!ed_10\", \"bunet2_aug1!ed_10\", \"nbunet_aug5!ed_10\", \"bunet2_aug5!ed_10\"]\n",
    "\n",
    "# used_model_names = [\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ff3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED_DATA = {\n",
    "#    \"Case001-1\": [\"175356\", \"176343\", \"177366\", \"178725\"],\n",
    "# }\n",
    "\n",
    "# used_model_names = [\"nbunet_aug1!ed_10\", \"nbunet_aug5!ed_10\", \"bunet2_aug1!ed_10\", \"bunet2_aug5!ed_10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c7f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR = [128, 128, 255]\n",
    "\n",
    "pixel_organ = 223\n",
    "p_color = 0.5\n",
    "\n",
    "FRAME_FORMAT = \"movieFrame_{}.png\"\n",
    "LABEL_FORMAT = \"label_{}.png\"\n",
    "\n",
    "START_FRAME = 3165\n",
    "END_FRAME = 3665\n",
    "\n",
    "ORGAN_PIXEL = 223\n",
    "\n",
    "# VIDEO_PATH = '../../accVideo/Case001/case001_2.MTS'\n",
    "# CASE_NAME = VIDEO_PATH.split(\"/\")[-2]\n",
    "# VIDEO_NAME = VIDEO_PATH.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "# COLOR = [255, 128, 128] #BGR\n",
    "HSV_CENTER = 75\n",
    "HSV_WIDTH = 75\n",
    "MODE = \"RGB\"\n",
    "\n",
    "H_IMG_SIZE = 1080\n",
    "W_IMG_SIZE = 1920\n",
    "SAVE_VIDEO_PATH = \"output_video/{}/{}.mp4\"\n",
    "SAVE_VIDEO_PATH2 = \"output_video/{}/{}_{}_{}_{}.mp4\"\n",
    "\n",
    "TIME_NAME = (datetime.datetime.now() + datetime.timedelta(hours=9)).strftime(\"20%y-%m-%d-%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00187fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pred2UncColor:\n",
    "    def __init__(self, u_min=0, u_max=181):\n",
    "        a = np.zeros((10, u_max, 3), dtype=np.uint8)\n",
    "        a[:, :, 0] = 255\n",
    "        b = cv2.cvtColor(a, cv2.COLOR_RGB2HSV_FULL)\n",
    "        for i in range(u_max):\n",
    "            b[:, (u_max-1)-i, 0] = i\n",
    "        c = cv2.cvtColor(b, cv2.COLOR_HSV2RGB_FULL)\n",
    "        self.u_max = u_max\n",
    "        self.u_min = u_min\n",
    "        self.color_bar = np.copy(c)\n",
    "        \n",
    "    def viz_bar(self):\n",
    "        plt.imshow(self.color_bar)\n",
    "        plt.xticks(np.arange(self.u_min, self.u_max, (self.u_max-1) / 5), [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        plt.yticks([])\n",
    "        plt.tick_params(labelsize=25)\n",
    "        plt.show()\n",
    "        \n",
    "    def save_bar(self, path):\n",
    "        plt.imshow(self.color_bar)\n",
    "        plt.xticks(np.arange(self.u_min, self.u_max, (self.u_max-1) / 5), [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        plt.yticks([])\n",
    "        plt.tick_params(labelsize=25)\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    def unc2color(self, unc):\n",
    "        u = np.around(unc * (self.u_max-1)).astype(np.int)\n",
    "        c = self.color_bar[0, u, :]\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ddd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2output(X_data_orig, Y_pred, mode=\"RGB\"):\n",
    "    if mode == \"RGB\":\n",
    "        Y_mask = np.where(Y_pred >= 0.5, 1, 0)\n",
    "        Y_mask_color = np.array([Y_mask * c for c in COLOR]).transpose(1, 2, 0)\n",
    "        output = X_data_orig.copy()\n",
    "        output = np.where(Y_mask[..., np.newaxis] == 1, p_color*Y_mask_color+(1-p_color)*X_data_orig, X_data_orig).astype(np.uint8)\n",
    "    elif mode == \"HSV\":\n",
    "        Y_mask_pred = HSV_CENTER + (Y_pred - 0.5) * (2 * HSV_WIDTH)\n",
    "        Y_mask_color = np.zeros((H_IMG_SIZE, W_IMG_SIZE, 3), dtype=np.uint8)\n",
    "        Y_mask_color[:, :, 0] = 255\n",
    "        Y_mask_hsv = cv2.cvtColor(Y_mask_color, cv2.COLOR_RGB2HSV_FULL)\n",
    "        Y_mask_hsv[..., 0] = Y_mask_pred\n",
    "        Y_mask = cv2.cvtColor(Y_mask_hsv, cv2.COLOR_HSV2RGB_FULL)\n",
    "        output = p_color * Y_mask + (1-p_color) * X_data_orig\n",
    "        output = output.astype(np.uint8)\n",
    "    return output\n",
    "\n",
    "def frame2tensor(frame):\n",
    "    frame = A.Resize(256, 256)(image=frame)[\"image\"]\n",
    "    tensor = transforms.ToTensor()(frame)\n",
    "    return tensor\n",
    "\n",
    "def case2ifold(case):\n",
    "    data = [\"Case001-1\", \"Case001-2\", \"Case002-1\", \"Case003-2\", \"Case004-1\", \"Case006-1\", \"Case007-1\", \"Case008-1\", \"Case008-2\", \"Case009-2\", \"Case010-2\"]\n",
    "    folds = {\n",
    "        0: {\n",
    "            \"train_data\": [data[4], data[5], data[6], data[7], data[8], data[9], data[10]],\n",
    "            \"valid_data\": [data[0], data[1], data[2], data[3]],\n",
    "            \"test_data\": [data[0], data[1], data[2], data[3]],\n",
    "        },\n",
    "        1: {\n",
    "            \"train_data\": [data[0], data[1], data[2], data[3], data[8], data[9], data[10]],\n",
    "            \"valid_data\": [data[4], data[5], data[6], data[7]],\n",
    "            \"test_data\": [data[4], data[5], data[6], data[7]],\n",
    "        },\n",
    "        2: {\n",
    "            \"train_data\": [data[0], data[1], data[2], data[3], data[4], data[5], data[6], data[7]],\n",
    "            \"valid_data\": [data[8], data[9], data[10]],\n",
    "            \"test_data\": [data[8], data[9], data[10]],\n",
    "        },\n",
    "    }\n",
    "    i_fold = -1\n",
    "    for i in range(len(folds)):\n",
    "        if case in folds[i][\"test_data\"]:\n",
    "            i_fold = i + 1\n",
    "    if i_fold == -1:\n",
    "        raise ValueError(\"Missing Data\")\n",
    "    return i_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3fbe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './output_img/{}'.format(TIME_NAME)\n",
    "\n",
    "try:\n",
    "    os.makedirs(img_dir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eeb8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2uc = Pred2UncColor()\n",
    "p2uc.save_bar(os.path.join(img_dir, \"color_bar.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for used_model_name in used_model_names:\n",
    "    print(\"+\"*30)\n",
    "    print(used_model_name)\n",
    "    print(\"+\"*30)\n",
    "    if used_model_name == \"label\":\n",
    "        img_outdir = os.path.join(img_dir, used_model_name)\n",
    "        try:\n",
    "            os.mkdir(img_outdir)\n",
    "        except:\n",
    "            pass\n",
    "        for case, frame_numbers in PRED_DATA.items():\n",
    "            for frame_number in frame_numbers:\n",
    "                frame_name = FRAME_FORMAT.format(frame_number)\n",
    "                frame_path = os.path.join(data_dir, case, \"movie\", frame_name)\n",
    "                frame = cv2.imread(frame_path)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                label_name = LABEL_FORMAT.format(frame_number)\n",
    "                label_path = os.path.join(data_dir, case, \"label\", label_name)\n",
    "                label = cv2.imread(label_path)[..., 0]\n",
    "#                 label = label / np.max(label)\n",
    "                label = np.where(label == ORGAN_PIXEL, 1, 0)\n",
    "\n",
    "                output = pred2output(frame, label, mode=MODE)\n",
    "                #####\n",
    "                case_dir = \"{}/{}\".format(img_outdir, case)\n",
    "                try:\n",
    "                    os.mkdir(case_dir)\n",
    "                except:\n",
    "                    pass\n",
    "                img_path = \"{}/{}\".format(case_dir, frame_name)\n",
    "                output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(img_path, output)\n",
    "\n",
    "        print(\"Done!\")\n",
    "        continue\n",
    "    #####\n",
    "\n",
    "    img_outdir = os.path.join(img_dir, used_model_name.split(\"!\")[0])\n",
    "    try:\n",
    "        os.mkdir(img_outdir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if used_model_name.find(\"unet\") == 0:\n",
    "        cfg.model_info.model = \"UNet\"\n",
    "        DROPOUT = False\n",
    "    elif used_model_name.find(\"aunet\") == 0:\n",
    "        cfg.model_info.model = \"AttentionUNet\"\n",
    "        DROPOUT = False\n",
    "    elif (used_model_name.find(\"bunet\") == 0) or (used_model_name.find(\"nbunet\") == 0):\n",
    "        cfg.model_info.model = \"BayesianUNet\"\n",
    "        option = used_model_name.split(\"!\")[1]\n",
    "        if option == \"nd\":\n",
    "            DROPOUT = False\n",
    "            N_INFERENCE = 1\n",
    "        else:\n",
    "            DROPOUT = True\n",
    "            N_INFERENCE = int(option.split(\"_\")[1])\n",
    "            DROPOUT_RATE = float(option.split(\"_\")[2]) / 10 if len(option.split(\"_\")) > 2 else 0.5\n",
    "    elif used_model_name.find(\"baunet\") == 0:\n",
    "        cfg.model_info.model = \"BayesianAttentionUNet\"\n",
    "        option = used_model_name.split(\"!\")[1]\n",
    "        if option == \"nd\":\n",
    "            DROPOUT = False\n",
    "            N_INFERENCE = 1\n",
    "        else:\n",
    "            DROPOUT = True\n",
    "            N_INFERENCE = int(option.split(\"_\")[1])\n",
    "            DROPOUT_RATE = float(option.split(\"_\")[2]) / 10 if len(option.split(\"_\")) > 2 else 0.5\n",
    "    else:\n",
    "        raise ValueError(\"未実装\")\n",
    "\n",
    "    if cfg.model_info.model in [\"UNet\"]:\n",
    "        model = Model[cfg.model_info.model](cfg.model_info.in_channels, cfg.model_info.out_channels)\n",
    "    elif cfg.model_info.model in [\"BayesianUNet\"]:\n",
    "        model = Model[cfg.model_info.model](cfg.model_info.in_channels, cfg.model_info.out_channels, DROPOUT_RATE)\n",
    "    elif cfg.model_info.model in [\"AttentionUNet\"]:\n",
    "        model = Model[cfg.model_info.model](cfg.model_info.in_channels, cfg.model_info.out_channels)\n",
    "    elif cfg.model_info.model in [\"BayesianAttentionUNet\"]:\n",
    "        model = Model[cfg.model_info.model](cfg.model_info.in_channels, cfg.model_info.out_channels)\n",
    "    else:\n",
    "        raise ValueError(\"未実装\")\n",
    "\n",
    "    if (cfg.device[:4] == \"cuda\") & (cfg.multi_gpu):\n",
    "        model = nn.DataParallel(model, device_ids=cfg.multi_device_ids)\n",
    "\n",
    "    if str(model.__class__) == \"<class 'torch.nn.parallel.data_parallel.DataParallel'>\":\n",
    "        print(\"parallel\")\n",
    "    else:\n",
    "        print(\"no parallel\")\n",
    "\n",
    "    ###\n",
    "    print(\"Making Images\")\n",
    "    inference_times = []\n",
    "    with torch.no_grad():\n",
    "        for case, frame_numbers in PRED_DATA.items():\n",
    "            i_fold = case2ifold(case)\n",
    "            model.load_state_dict(torch.load(cfg.model_info.save_model_path.format(used_model_name.split(\"!\")[0], \"{}_fold\".format(i_fold))))\n",
    "            model.eval()\n",
    "            if DROPOUT:\n",
    "                if str(model.__class__) == \"<class 'torch.nn.parallel.data_parallel.DataParallel'>\":\n",
    "                    model.module.enable_dropout()\n",
    "                else:\n",
    "                    model.enable_dropout()\n",
    "            model = model.to(cfg.device)\n",
    "\n",
    "            for frame_number in frame_numbers:\n",
    "                frame_name = FRAME_FORMAT.format(frame_number)\n",
    "                frame_path = os.path.join(data_dir, case, \"movie\", frame_name)\n",
    "                frame = cv2.imread(frame_path)\n",
    "                if frame is None:\n",
    "                    print(frame_path)\n",
    "                    ValueError(\"Frame is None\")\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                #####\n",
    "                frame = resize9x16(frame)\n",
    "                X_data_orig = frame.copy()\n",
    "                if X_data_orig.shape[:2] != (H_IMG_SIZE, W_IMG_SIZE):\n",
    "                    print(\"Error\")\n",
    "                X_data = frame2tensor(frame)\n",
    "                X_data = X_data.to(cfg.device).unsqueeze(0)\n",
    "                start_time = time.time()\n",
    "\n",
    "                if cfg.model_info.model in [\"BayesianUNet\"]:\n",
    "                    Y_preds = []\n",
    "                    for j in range(N_INFERENCE):\n",
    "                        Y_pred = model(X_data)\n",
    "                        Y_pred = Y_pred.sigmoid()\n",
    "                        Y_preds.append(Y_pred)\n",
    "                    Y_pred = torch.stack(Y_preds).mean(axis=0)\n",
    "                    # Y_pred = torch.stack(Y_preds).median(axis=0).values\n",
    "                    # Y_pred = torch.stack(Y_preds).min(axis=0).values\n",
    "                    \n",
    "                    Y_uncertainty = Y_preds2entropy(Y_preds, cfg.device)\n",
    "                    Y_uncertainty_max = Y_preds2entropymax(Y_preds, cfg.device)\n",
    "                else:\n",
    "                    Y_pred = model(X_data)\n",
    "                    Y_pred = Y_pred.sigmoid()\n",
    "                    Y_uncertainty = None\n",
    "                    Y_uncertainty_max = None\n",
    "\n",
    "                end_time = time.time()\n",
    "                inference_times.append(end_time - start_time)\n",
    "                Y_pred = Y_pred.cpu().squeeze().numpy()\n",
    "                Y_pred = resize9x16(Y_pred)\n",
    "\n",
    "                output = pred2output(X_data_orig, Y_pred, mode=MODE)\n",
    "                #####\n",
    "                case_dir = \"{}/{}\".format(img_outdir, case)\n",
    "                try:\n",
    "                    os.mkdir(case_dir)\n",
    "                except:\n",
    "                    pass\n",
    "                img_path = \"{}/{}\".format(case_dir, frame_name)\n",
    "                output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(img_path, output)\n",
    "                \n",
    "                if Y_uncertainty is not None:\n",
    "                    Y_uncertainty = Y_uncertainty.cpu().squeeze().numpy()\n",
    "                    Y_uncertainty = resize9x16(Y_uncertainty)\n",
    "                    output = p2uc.unc2color(Y_uncertainty)\n",
    "                    output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(\"{}/uncertainty-{}\".format(case_dir, frame_name), output)\n",
    "                    \n",
    "                if Y_uncertainty_max is not None:\n",
    "                    Y_uncertainty_max = Y_uncertainty_max.cpu().squeeze().numpy()\n",
    "                    Y_uncertainty_max = resize9x16(Y_uncertainty_max)\n",
    "                    output = p2uc.unc2color(Y_uncertainty_max)\n",
    "                    output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(\"{}/uncertainty_max-{}\".format(case_dir, frame_name), output)\n",
    "\n",
    "    ####\n",
    "    print(\"Average Inference Time {}(s)\".format(np.mean(inference_times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d0191",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for case, frame_numbers in PRED_DATA.items():\n",
    "    for frame_number in frame_numbers:\n",
    "        fig = plt.figure(figsize=(len(used_model_names) * 16, 9))\n",
    "        for i, used_model_name in enumerate(used_model_names):\n",
    "            # if used_model_name == \"label\":\n",
    "            #     frame_name = LABEL_FORMAT.format(frame_number)\n",
    "            #     frame_path = os.path.join(data_dir, case, \"label\", frame_name)\n",
    "            #     frame = cv2.imread(frame_path)\n",
    "            #     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # else:\n",
    "            frame_name = FRAME_FORMAT.format(frame_number)\n",
    "            frame_path = os.path.join(img_dir, used_model_name.split(\"!\")[0], case, frame_name)\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                print(frame_path)\n",
    "                raise ValueError(\"Frame is None\")\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            ax = fig.add_subplot(1, len(used_model_names), i+1)\n",
    "            ax.imshow(frame)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        save_path = os.path.join(img_dir, case + \"_\" + frame_name)\n",
    "        ax.set_title(\"{}: {}\".format(case, frame_number), fontsize=40)\n",
    "#         plt.savefig(save_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(os.path.dirname(img_dir)))\n",
    "print(\"Please Delete Unneed Folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28aac38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for case, frame_numbers in PRED_DATA.items():\n",
    "    for frame_number in frame_numbers:\n",
    "        fig = plt.figure(figsize=(len(used_model_names) * 16, 9))\n",
    "        \n",
    "        uncertainty_model_names = list(filter(lambda x: (x.find(\"bunet\") == 0) or (x.find(\"nbunet\") == 0), used_model_names))\n",
    "        for i, uncertainty_model_name in enumerate(uncertainty_model_names):\n",
    "            # if used_model_name == \"label\":\n",
    "            #     frame_name = LABEL_FORMAT.format(frame_number)\n",
    "            #     frame_path = os.path.join(data_dir, case, \"label\", frame_name)\n",
    "            #     frame = cv2.imread(frame_path)\n",
    "            #     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # else:\n",
    "            frame_name = FRAME_FORMAT.format(frame_number)\n",
    "            frame_path = os.path.join(img_dir, uncertainty_model_name.split(\"!\")[0], case, frame_name)\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                print(frame_path)\n",
    "                raise ValueError(\"Frame is None\")\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            ax = fig.add_subplot(1,2*len(used_model_names), 2*i+1)\n",
    "            ax.imshow(frame)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "            frame_name = FRAME_FORMAT.format(frame_number)\n",
    "            frame_path = os.path.join(img_dir, uncertainty_model_name.split(\"!\")[0], case, \"uncertainty-{}\".format(frame_name))\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                print(frame_path)\n",
    "                raise ValueError(\"Frame is None\")\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            ax = fig.add_subplot(1,2*len(used_model_names), 2*i+2)\n",
    "            ax.imshow(frame)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "        save_path = os.path.join(img_dir, case + \"_\" + frame_name)\n",
    "        ax.set_title(\"{}: {}\".format(case, frame_number), fontsize=40)\n",
    "#         plt.savefig(save_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8eab63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for case, frame_numbers in PRED_DATA.items():\n",
    "    for frame_number in frame_numbers:\n",
    "        fig = plt.figure(figsize=(len(used_model_names) * 16, 9))\n",
    "        \n",
    "        uncertainty_model_names = list(filter(lambda x: (x.find(\"bunet\") == 0) or (x.find(\"nbunet\") == 0), used_model_names))\n",
    "        for i, uncertainty_model_name in enumerate(uncertainty_model_names):\n",
    "            # if used_model_name == \"label\":\n",
    "            #     frame_name = LABEL_FORMAT.format(frame_number)\n",
    "            #     frame_path = os.path.join(data_dir, case, \"label\", frame_name)\n",
    "            #     frame = cv2.imread(frame_path)\n",
    "            #     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # else:\n",
    "            frame_name = FRAME_FORMAT.format(frame_number)\n",
    "            frame_path = os.path.join(img_dir, uncertainty_model_name.split(\"!\")[0], case, frame_name)\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                print(frame_path)\n",
    "                raise ValueError(\"Frame is None\")\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            ax = fig.add_subplot(1,2*len(used_model_names), 2*i+1)\n",
    "            ax.imshow(frame)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "            frame_name = FRAME_FORMAT.format(frame_number)\n",
    "            frame_path = os.path.join(img_dir, uncertainty_model_name.split(\"!\")[0], case, \"uncertainty_max-{}\".format(frame_name))\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                print(frame_path)\n",
    "                raise ValueError(\"Frame is None\")\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            ax = fig.add_subplot(1,2*len(used_model_names), 2*i+2)\n",
    "            ax.imshow(frame)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "        save_path = os.path.join(img_dir, case + \"_\" + frame_name)\n",
    "        ax.set_title(\"{}: {}\".format(case, frame_number), fontsize=40)\n",
    "#         plt.savefig(save_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c116a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: (x.find(\"bunet\") == 0) or (x.find(\"nbunet\") == 0), used_model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a9414f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
